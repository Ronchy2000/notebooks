{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Matrix Factorization with Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an attempt to reproduce [this ICML 2009 paper](http://people.ee.duke.edu/~lcarin/MatrixFactorization.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "DEVICE = \"/cpu:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulated data\n",
    "import numpy as np\n",
    "\n",
    "N = 3  # items\n",
    "D = 10  # users\n",
    "q = 2  # latent dimension\n",
    "true_alpha_x = 0.05\n",
    "true_alpha_w = 0.02\n",
    "true_sigma = 0.001\n",
    "\n",
    "X = np.random.randint(50, size=(N, q))\n",
    "W = np.random.normal(0, true_alpha_w, (D, q))\n",
    "rating_rows = []\n",
    "for i in range(N):\n",
    "    rating_rows.append(np.random.multivariate_normal(W.dot(X[i, :]), true_sigma ** 2 * np.eye(D)))\n",
    "Y = np.array(rating_rows)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "dataset = coo_matrix(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare batches\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for i_train, i_test in splitter.split(dataset.data):\n",
    "    train = coo_matrix((dataset.data[i_train], (dataset.row[i_train], dataset.col[i_train])), shape=(N, D)).tocsc()\n",
    "    test = coo_matrix((dataset.data[i_test], (dataset.row[i_test], dataset.col[i_test])), shape=(N, D)).tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[-1.0362237  -0.58233791]\n",
      "[1]\n",
      "[ 1.10123861]\n",
      "[0]\n",
      "[ 0.1269993]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for user_id in range(5):\n",
    "    # print(test[:, user_id].getnnz())\n",
    "    print(test[:, user_id].indices)\n",
    "    print(test[:, user_id].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_batch = tf.placeholder(tf.int32, shape=[None], name=\"id_user\")\n",
    "item_batch = tf.placeholder(tf.int32, shape=[None], name=\"id_item\")\n",
    "rate_batch = tf.placeholder(tf.float32, shape=[None, None], name=\"rate\")\n",
    "pred_batch = tf.placeholder(tf.int32, shape=[None], name=\"id_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel(X, Y):\n",
    "    return tf.matmul(X, tf.transpose(Y))\n",
    "\n",
    "class MFGP:\n",
    "    def __init__(self):\n",
    "        with tf.device(DEVICE):\n",
    "            with tf.variable_scope(\"conv1\"):\n",
    "                self.sigma = tf.Variable(tf.random_normal([1]), name=\"sigma\")\n",
    "                self.alpha_x = tf.Variable(tf.random_normal([1]), name=\"alpha_x\")\n",
    "                self.alpha_w = tf.Variable(tf.random_normal([1]), name=\"alpha_w\")\n",
    "                self.w_user = tf.Variable(tf.random_normal([D, q], stddev=0.2), name=\"embd_user\")\n",
    "                self.x_item = tf.Variable(tf.random_normal([N, q], stddev=0.2), name=\"embd_item\")\n",
    "        # embd_user = tf.nn.embedding_lookup(w_user, user_batch, name=\"embedding_user\")\n",
    "        # embd_item = tf.nn.embedding_lookup(x_item, item_batch, name=\"embedding_item\")\n",
    "\n",
    "    def debug(self, sess, item_batch):\n",
    "        sess.run(init_op)\n",
    "        print(sess.run(self.x_item))\n",
    "        print(sess.run(item_batch))        \n",
    "\n",
    "    def predict(self, user_batch, item_batch, rate_batch, pred_batch):\n",
    "        with tf.device(DEVICE):\n",
    "            x_batch = tf.nn.embedding_lookup(self.x_item, item_batch)\n",
    "            x_pred = tf.nn.embedding_lookup(self.x_item, pred_batch)\n",
    "            N_j = tf.shape(item_batch)[0]\n",
    "            cov = kernel(x_batch, x_batch) + self.sigma ** 2 * tf.eye(N_j)\n",
    "            s = tf.matmul(tf.matrix_inverse(cov), kernel(x_batch, x_pred))\n",
    "            prediction = tf.matmul(tf.transpose(s), rate_batch)\n",
    "        return tf.reshape(prediction, [-1])\n",
    "\n",
    "    def get_loss(self, user_batch, item_batch, rate_batch):\n",
    "        with tf.device(DEVICE):\n",
    "            x_batch = tf.nn.embedding_lookup(self.x_item, item_batch)\n",
    "            N_j = tf.shape(item_batch)[0]\n",
    "            cov = 1/self.alpha_w * kernel(x_batch, x_batch) + self.sigma ** 2 * tf.eye(N_j)\n",
    "            #loss3 = tf.matrix_inverse(cov)\n",
    "            #loss2 = tf.matmul(tf.matrix_inverse(cov), rate_batch)\n",
    "            loss = (tf.cast(N_j, tf.float32) * tf.log(tf.matrix_determinant(cov))\n",
    "                    + tf.reshape(tf.matmul(tf.transpose(rate_batch), tf.matmul(tf.matrix_inverse(cov), rate_batch)), []))\n",
    "        return loss\n",
    "\n",
    "    def optimization(self, user_batch, item_batch, rate_batch, learning_rate=0.001):\n",
    "        global_step = tf.train.get_global_step()\n",
    "        assert global_step is not None\n",
    "        with tf.device(DEVICE):\n",
    "            # cost_l2 = tf.nn.l2_loss(tf.subtract(infer, rate_batch))\n",
    "            # penalty = tf.constant(reg, dtype=tf.float32, shape=[], name=\"l2\")\n",
    "            # cost = tf.add(cost_l2, tf.multiply(regularizer, penalty))\n",
    "            loss = self.get_loss(user_batch, item_batch, rate_batch)\n",
    "            train_op = tf.train.MomentumOptimizer(learning_rate, 0.9, use_nesterov=True).minimize(loss, global_step=global_step)\n",
    "        return loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id | epoch | train_error | val_error | elapsed_time\n",
      "train [-0.00015972] [-0.01218857]\n",
      "test [ -4.26896499e-04  -3.86088650e-05] [-1.0362237  -0.58233791]\n",
      "user= 0 epoch=  0 train_err=0.012029 test_err=0.840222 his_loss=-0.196617, sum_losses=-2.362280, all_losses=[-0.19661705, -0.22379178, 0.12683764, -0.21289325, -0.99248475, 0.71130639, -0.13664854, -0.49668658, -0.37515742, -0.566145]\n",
      "train [ 0.11828238  0.0470581 ] [ 0.55765551  0.31935937]\n",
      "test [ 0.03250591] [ 0.1269993]\n",
      "user= 2 epoch=  0 train_err=0.353820 test_err=0.094493 his_loss=-3.330988, sum_losses=-60.031102, all_losses=[-1.3122668, -3.7542503, -3.3309882, -8.4445868, -10.412377, -1.7489336, -8.280901, -9.1877365, -4.2057743, -9.3532877]\n",
      "train [-0.00161645 -0.07598279 -0.03295146] [-0.0175215  -0.08341457 -0.04742625]\n",
      "test [] []\n",
      "no test for user= 4\n",
      "train [ 0.00172567  0.02016635  0.00294806] [ 0.0008417   0.82922637  0.4636775 ]\n",
      "test [] []\n",
      "no test for user= 6\n",
      "train [-0.00929633  0.00928263] [-0.03902631  0.50912533]\n",
      "test [ 0.00223476] [ 0.91215863]\n",
      "user= 8 epoch=  0 train_err=0.423304 test_err=0.909924 his_loss=11.058426, sum_losses=171.721320, all_losses=[2.7624276, 11.066952, 11.092617, 24.936575, 24.88653, 11.142195, 24.942196, 24.919067, 11.058426, 24.914335]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jin/Sites/mangaki/venv/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/jin/Sites/mangaki/venv/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train [ -5.63762551e-05] [-0.01218857]\n",
      "test [ -3.73272283e-04   2.81558077e-05] [-1.0362237  -0.58233791]\n",
      "user= 0 epoch= 25 train_err=0.348839 test_err=0.840279 his_loss=10.832930, sum_losses=674.223742, all_losses=[10.83293, 43.329964, 43.603813, 97.904327, 97.904312, 43.605469, 97.904327, 97.90432, 43.32996, 97.90432]\n",
      "train [ 0.19459763 -0.00166854] [ 0.55765551  0.31935937]\n",
      "test [ 0.01042591] [ 0.1269993]\n",
      "user= 2 epoch= 25 train_err=0.349171 test_err=0.116573 his_loss=43.602654, sum_losses=674.210590, all_losses=[10.83284, 43.329613, 43.602654, 97.902321, 97.902306, 43.604301, 97.902321, 97.902313, 43.329609, 97.902313]\n",
      "train [-0.00162435 -0.02942814  0.00028506] [-0.0175215  -0.08341457 -0.04742625]\n",
      "test [] []\n",
      "no test for user= 4\n",
      "train [ 0.01547016  0.28914541 -0.00246485] [ 0.0008417   0.82922637  0.4636775 ]\n",
      "test [] []\n",
      "no test for user= 6\n",
      "train [-0.00135513  0.00081298] [-0.03902631  0.50912533]\n",
      "test [-0.0041378] [ 0.91215863]\n",
      "user= 8 epoch= 25 train_err=0.349291 test_err=0.916296 his_loss=43.328407, sum_losses=674.163998, all_losses=[10.832535, 43.328411, 43.598515, 97.895203, 97.895187, 43.600147, 97.895203, 97.895195, 43.328407, 97.895195]\n",
      "train [ -5.69913027e-05] [-0.01218857]\n",
      "test [ -3.77394404e-04   2.84630732e-05] [-1.0362237  -0.58233791]\n",
      "user= 0 epoch= 50 train_err=0.347677 test_err=0.840276 his_loss=10.820718, sum_losses=672.851243, all_losses=[10.820718, 43.281559, 43.490097, 97.697197, 97.697182, 43.49136, 97.697197, 97.697189, 43.281555, 97.697189]\n",
      "train [ 0.19600242 -0.00167883] [ 0.55765551  0.31935937]\n",
      "test [ 0.01049797] [ 0.1269993]\n",
      "user= 2 epoch= 50 train_err=0.347846 test_err=0.116501 his_loss=43.489494, sum_losses=672.843411, all_losses=[10.82063, 43.281208, 43.489494, 97.69603, 97.696014, 43.490757, 97.69603, 97.696022, 43.281204, 97.696022]\n",
      "train [-0.00163573 -0.0296404   0.00028695] [-0.0175215  -0.08341457 -0.04742625]\n",
      "test [] []\n",
      "no test for user= 4\n",
      "train [ 0.01557662  0.29123202 -0.00247975] [ 0.0008417   0.82922637  0.4636775 ]\n",
      "test [] []\n",
      "no test for user= 6\n",
      "train [-0.00136992  0.00082187] [-0.03902631  0.50912533]\n",
      "test [-0.00418333] [ 0.91215863]\n",
      "user= 8 epoch= 50 train_err=0.347915 test_err=0.916342 his_loss=43.280003, sum_losses=672.815910, all_losses=[10.820328, 43.280006, 43.487362, 97.691925, 97.69191, 43.488617, 97.691925, 97.691917, 43.280003, 97.691917]\n",
      "train [ -5.76360544e-05] [-0.01218857]\n",
      "test [ -3.81701393e-04   2.87852454e-05] [-1.0362237  -0.58233791]\n",
      "user= 0 epoch= 75 train_err=0.347058 test_err=0.840274 his_loss=10.808477, sum_losses=671.836084, all_losses=[10.808477, 43.232777, 43.414127, 97.546547, 97.546532, 43.415226, 97.546547, 97.546539, 43.232773, 97.546539]\n",
      "train [ 0.19745676 -0.00168943] [ 0.55765551  0.31935937]\n",
      "test [ 0.01057264] [ 0.1269993]\n",
      "user= 2 epoch= 75 train_err=0.347172 test_err=0.116427 his_loss=43.413639, sum_losses=671.829269, all_losses=[10.808388, 43.232422, 43.413639, 97.54554, 97.545525, 43.414734, 97.54554, 97.545532, 43.232418, 97.545532]\n",
      "train [-0.00164752 -0.02986011  0.00028891] [-0.0175215  -0.08341457 -0.04742625]\n",
      "test [] []\n",
      "no test for user= 4\n",
      "train [ 0.01568691  0.29339167 -0.00249509] [ 0.0008417   0.82922637  0.4636775 ]\n",
      "test [] []\n",
      "no test for user= 6\n",
      "train [-0.00138541  0.00083118] [-0.03902631  0.50912533]\n",
      "test [-0.00423086] [ 0.91215863]\n",
      "user= 8 epoch= 75 train_err=0.347217 test_err=0.916389 his_loss=43.231201, sum_losses=671.805657, all_losses=[10.808084, 43.231205, 43.411919, 97.542053, 97.542038, 43.413013, 97.542053, 97.542046, 43.231201, 97.542046]\n",
      "learned\n",
      "[-220.897995]\n",
      "[ 6.4371376]\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "\n",
    "mfgp = MFGP()\n",
    "prediction = mfgp.predict(user_batch, item_batch, rate_batch, pred_batch)\n",
    "\n",
    "global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "loss, train_op = mfgp.optimization(user_batch, item_batch, rate_batch, learning_rate=0.01)\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    summary_writer = tf.summary.FileWriter(logdir=\"/tmp/log_tf\", graph=sess.graph)\n",
    "    print(\" | \".join([\"user_id\", \"epoch\", \"train_error\", \"val_error\", \"elapsed_time\"]))\n",
    "    errors = deque()\n",
    "    start = time.time()\n",
    "    for epoch in range(100):\n",
    "        for user_id in range(D):\n",
    "            train_batch = train[:, user_id]\n",
    "            N_j = train_batch.getnnz()\n",
    "            users, items, rates = [user_id] * N_j, train_batch.indices, train_batch.data\n",
    "            _, pred = sess.run([train_op, prediction], feed_dict={user_batch: users,\n",
    "                                                                  item_batch: items,\n",
    "                                                                  rate_batch: np.array(rates).reshape(N_j, 1),\n",
    "                                                                  pred_batch: items})\n",
    "            errors.extend(np.power(pred - rates, 2))\n",
    "            if user_id % 2 == 0 and epoch % 25 == 0:\n",
    "                print('train', pred[:5], rates[:5])\n",
    "                #print('all errors', errors)\n",
    "                train_err = np.sqrt(np.mean(errors))\n",
    "                test_err2 = np.array([])\n",
    "                # for user_id in range(D):\n",
    "                # train_batch = train[:]\n",
    "                test_batch = test[:, user_id]\n",
    "                preds = test_batch.indices\n",
    "                truth = test_batch.data\n",
    "                # true_pred = users, items, rates = [user_id] * N_j, test_batch.indices, test_batch.data, train\n",
    "                this_error, pred = sess.run([loss, prediction], feed_dict={user_batch: users,\n",
    "                                                                item_batch: items,\n",
    "                                                                rate_batch: np.array(rates).reshape(len(rates), 1),\n",
    "                                                                pred_batch: preds})\n",
    "                print('test', pred[:5], truth[:5])\n",
    "                all_errors = []\n",
    "                for test_user_id in range(D):\n",
    "                    test_batch = train[:, test_user_id]\n",
    "                    test_N_j = test_batch.getnnz()\n",
    "                    test_users, test_items, test_rates = np.array([test_user_id] * test_N_j), test_batch.indices, np.array(test_batch.data).reshape(test_N_j, 1)\n",
    "                    this_user_error = sess.run(loss, feed_dict={user_batch: test_users, item_batch: test_items, rate_batch: test_rates})\n",
    "                    all_errors.append(this_user_error)\n",
    "                test_err2 = np.append(test_err2, np.power(pred - truth, 2))\n",
    "                end = time.time()\n",
    "                test_err = np.sqrt(np.mean(test_err2))\n",
    "                if len(preds):\n",
    "                    print(\"user={:2d} epoch={:3d} train_err={:f} test_err={:f} his_loss={:f}, sum_losses={:f}, all_losses={:s}\".format(user_id, epoch, train_err, test_err,\n",
    "                                                       this_error, sum(all_errors), str(all_errors)))\n",
    "                else:\n",
    "                    print('no test for user={:2d}'.format(user_id))\n",
    "                start = end\n",
    "    print('learned')\n",
    "    print(mfgp.sigma.eval())\n",
    "    print(mfgp.alpha_w.eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
